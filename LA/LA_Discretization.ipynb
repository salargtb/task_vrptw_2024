{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook includes codes for LA-Discretization algorithms developed in Mandal et al. (2024) paper. \n",
    "### Please note that modules and functions are listed in util_LA.py script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we import the required packages and modules from util_baseline.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "from util_LA import travel_time_computer, generate_E_star, create_buckets, create_neighborhoods, generate_P_plus, creating_efficient_frontier, construct_R, construct_capacity_graph, construct_time_graph\n",
    "from util_LA import create_E_u_star_dict, calculate_a_wvr, calculate_E_star_uw_dict, calculate_aw_star_r, mip_solver, lp_relaxation_solver\n",
    "from util_LA import merge_buckets, compute_k, expand_capacity_buckets, expand_time_buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for different experiments is imported from excel file. We also add another row for the ending node. The ending with its attributes are added to the last row of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('R102.csv')\n",
    "df = df.iloc[:51]\n",
    "# Adding ending node depot\n",
    "new_row = df.iloc[0].copy() \n",
    "new_row[\"CUST NO.\"] = len(df) + 1\n",
    "new_row_df = pd.DataFrame([new_row])\n",
    "df = pd.concat([df, new_row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting data of customers and depots from the dataframe\n",
    "node_data = {}\n",
    "for idx, row in df.iterrows():\n",
    "    cid = int(row['CUST NO.'])  # or keep as float if you prefer\n",
    "    node_data[cid] = {\n",
    "        'x':        float(row['XCOORD.']),\n",
    "        'y':        float(row['YCOORD.']),\n",
    "        'demand':   float(row['DEMAND']),\n",
    "        'early':    float(row['READY TIME']),\n",
    "        'late':      float(row['DUE DATE']),\n",
    "        'service':  float(row['SERVICE TIME'])\n",
    "    }\n",
    "\n",
    "# Vehicle maximum time and capacity capacity\n",
    "d0 = 200.0\n",
    "t0 = node_data[1][\"late\"] # this is based on Solomon dataset. The total time is equal to uppper bound of depot time window\n",
    "k = 15\n",
    "\n",
    "# Getting time windows based on bedget remaining logic\n",
    "for u in node_data:\n",
    "    node_data[u][\"t_plus_budget\"] = t0 - node_data[u][\"early\"]  # Adjusted t^+ for budget logic\n",
    "    node_data[u][\"t_minus_budget\"] = t0 - node_data[u][\"late\"]  # Adjusted t^- for budget logic\n",
    "\n",
    "\n",
    "# Indices for depots\n",
    "alpha = 1\n",
    "bar_alpha = len(node_data)  \n",
    "\n",
    "# Extracting all customers from all nodes\n",
    "all_nodes = list(node_data.keys())  \n",
    "customers = [n for n in all_nodes if n not in (alpha, bar_alpha)]\n",
    "\n",
    "customer_demands = {n: node_data[n]['demand'] for n in customers}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_star = generate_E_star(all_nodes, node_data, alpha, bar_alpha, d0)\n",
    "\n",
    "# Create the buckets dictionary\n",
    "ds = 5   # used as increment factor for creating capacity buckets\n",
    "ts = 50  # used as increment factor for creating time buckets\n",
    "Du = {}  # initalizing capacity buckets\n",
    "Tu = {}  # initalizing time buckets\n",
    "for u in customers:\n",
    "    Du[u] = create_buckets(customer_demands[u], ds, d0)\n",
    "    Tu[u] = create_buckets(node_data[u][\"t_minus_budget\"], ts, node_data[u][\"t_plus_budget\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The input parameters are initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inital parameters\n",
    "k = 6\n",
    "iter_max = 10\n",
    "min_inc = 1\n",
    "zeta = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here eficient frontier is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = create_neighborhoods(node_data, alpha+1, bar_alpha-1, k, t0, d0)\n",
    "\n",
    "P_plus = generate_P_plus(neighborhoods, node_data)\n",
    "\n",
    "\n",
    "R_dict = creating_efficient_frontier(node_data, P_plus)\n",
    "\n",
    "R = {}\n",
    "for u in customers:\n",
    "    R[u] = construct_R(u, R_dict, neighborhoods[u], bar_alpha, max_subset_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LA-discretization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_since_reset = 0\n",
    "last_lp_val = -9999999\n",
    "N_u = neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2602720\n",
      "Academic license - for non-commercial use only - expires 2025-12-22\n",
      "852.3220338679753\n",
      "904.6647389522201\n",
      "931.001042550078\n",
      "934.2124000000006\n",
      "934.2124000000006\n",
      "935.5924000000005\n",
      "935.5924000000005\n",
      "935.5924000000005\n",
      "935.5924000000005\n",
      "935.5924000000005\n",
      "935.5924000000005\n",
      "935.5924000000005\n",
      "935.5924000000005\n",
      "935.5924000000005\n",
      "935.5924000000005\n"
     ]
    }
   ],
   "source": [
    "while iter_since_reset < iter_max:\n",
    "    prev_N_u = copy.deepcopy(N_u)\n",
    "    prev_Tu = copy.deepcopy(Tu)\n",
    "    prev_Du = copy.deepcopy(Du)\n",
    "    # Step 5-7: Reset neighborhoods if iter_since_reset >= zeta\n",
    "    if iter_since_reset >= zeta:\n",
    "        for u in customers:\n",
    "            N_u [u] = neighborhoods[u]\n",
    "\n",
    "    # Step 8: Solve LP relaxation\n",
    "    # zD, zT, lp_objective_value = lp_relaxation_solver(all_nodes, customers, customer_demands, node_data, E_star, t0, d0, alpha, bar_alpha, R, Du, Tu, N_u)\n",
    "    capacity_duals, time_duals, pi_uwvk, pi_uwk, zD, zT, lp_objective_value = lp_relaxation_solver(all_nodes, customers, customer_demands, node_data, E_star, t0, d0, alpha, bar_alpha, R, Du, Tu, N_u)\n",
    "\n",
    "    # Step 9-15: Check for LP improvement and apply contraction\n",
    "    if lp_objective_value > last_lp_val + min_inc:\n",
    "        # Line 10-12: Apply contraction operations\n",
    "        for u in customers:\n",
    "   \n",
    "            Du[u] = merge_buckets(u, Du[u], capacity_duals)\n",
    "            Tu[u] = merge_buckets(u, Tu[u], time_duals)\n",
    "            k_u = compute_k(u, N_u[u], pi_uwk, pi_uwvk, E_star)\n",
    "            N_u[u] = N_u[u][:k_u] if k_u < len(N_u[u]) else N_u[u]\n",
    "        # breakpoint()            \n",
    "            # print(f'capacity bucket is : {Du[u]}')\n",
    "            # print(f'time bucket is : {Tu[u]}')\n",
    "        # Update LP objective and iteration count\n",
    "        last_lp_val = lp_objective_value\n",
    "        iter_since_reset = 0\n",
    "    # Step 16-17: Expand buckets for sufficiency\n",
    "    Du = expand_capacity_buckets(Du, zD, customer_demands, d0, alpha, bar_alpha)\n",
    "    Tu = expand_time_buckets(Tu, zT, travel_time_computer, node_data, t0, alpha, bar_alpha)\n",
    "    # print('**********************************************************************')\n",
    "    # print(f'capacity bucket is : {Du}')\n",
    "    # print(f'time bucket is : {Tu}')\n",
    "    # Increment iteration count\n",
    "    iter_since_reset += 1\n",
    "    # N_u == prev_N_u and Tu == prev_Tu and Du == prev_Du\n",
    "    if N_u == prev_N_u and Tu == prev_Tu and Du == prev_Du:\n",
    "        break\n",
    "    print(last_lp_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, the mixed integer linear programming model is solved using the adjusted Du, Tu, and N_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in customers:\n",
    "    Du[u] = merge_buckets(u, Du[u], capacity_duals)\n",
    "    Tu[u] = merge_buckets(u, Tu[u], time_duals)\n",
    "    k_u = compute_k(u, N_u[u], pi_uwk, pi_uwvk, E_star)\n",
    "    N_u[u] = N_u[u][:k_u] if k_u < len(N_u[u]) else N_u[u]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 1200\n",
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (mac64[x86] - Darwin 22.1.0 22A400)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  1200\n",
      "\n",
      "Optimize a model with 6277 rows, 46760 columns and 65075 nonzeros\n",
      "Model fingerprint: 0xd06bf3af\n",
      "Variable types: 45328 continuous, 1432 integer (1432 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+02]\n",
      "  Objective range  [5e+00, 8e+01]\n",
      "  Bounds range     [1e+00, 2e+02]\n",
      "  RHS range        [1e+00, 2e+02]\n",
      "Presolve removed 2319 rows and 34728 columns\n",
      "Presolve time: 0.40s\n",
      "Presolved: 3958 rows, 12032 columns, 84675 nonzeros\n",
      "Variable types: 10579 continuous, 1453 integer (1434 binary)\n",
      "Found heuristic solution: objective 1870.9500000\n",
      "\n",
      "Root relaxation: objective 9.114300e+02, 3123 iterations, 0.17 seconds (0.23 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0     911.4300000  911.43000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (3123 simplex iterations) in 0.68 seconds (0.66 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 911.43 1870.95 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.114300000000e+02, best bound 9.114300000000e+02, gap 0.0000%\n",
      "Optimal solution found in 0.6891 seconds.\n",
      "Optimal objective value: 911.430\n",
      "Used arcs:\n",
      "  1 -> 12, cost=33.54\n",
      "  1 -> 15, cost=32.02\n",
      "  1 -> 19, cost=15.81\n",
      "  1 -> 22, cost=18.03\n",
      "  1 -> 28, cost=5.00\n",
      "  1 -> 29, cost=6.32\n",
      "  1 -> 37, cost=41.40\n",
      "  1 -> 38, cost=21.21\n",
      "  1 -> 41, cost=11.18\n",
      "  1 -> 46, cost=29.15\n",
      "  1 -> 51, cost=16.97\n",
      "  2 -> 31, cost=11.05\n",
      "  3 -> 52, cost=18.00\n",
      "  4 -> 52, cost=22.36\n",
      "  5 -> 26, cost=10.00\n",
      "  6 -> 52, cost=20.62\n",
      "  7 -> 52, cost=11.18\n",
      "  8 -> 52, cost=21.21\n",
      "  9 -> 47, cost=9.43\n",
      "  10 -> 36, cost=9.43\n",
      "  11 -> 32, cost=8.06\n",
      "  12 -> 20, cost=7.07\n",
      "  13 -> 52, cost=15.00\n",
      "  14 -> 52, cost=11.18\n",
      "  15 -> 45, cost=5.66\n",
      "  16 -> 42, cost=12.17\n",
      "  17 -> 7, cost=18.03\n",
      "  18 -> 6, cost=10.00\n",
      "  19 -> 11, cost=22.36\n",
      "  20 -> 50, cost=12.04\n",
      "  21 -> 33, cost=10.77\n",
      "  22 -> 40, cost=17.00\n",
      "  23 -> 5, cost=14.14\n",
      "  24 -> 23, cost=11.18\n",
      "  25 -> 13, cost=15.00\n",
      "  26 -> 27, cost=22.36\n",
      "  27 -> 52, cost=11.18\n",
      "  28 -> 2, cost=10.82\n",
      "  29 -> 30, cost=23.54\n",
      "  30 -> 25, cost=7.07\n",
      "  31 -> 21, cost=7.07\n",
      "  32 -> 52, cost=17.46\n",
      "  33 -> 52, cost=34.00\n",
      "  34 -> 10, cost=8.25\n",
      "  35 -> 4, cost=14.14\n",
      "  36 -> 35, cost=10.20\n",
      "  37 -> 48, cost=7.21\n",
      "  38 -> 43, cost=8.94\n",
      "  39 -> 44, cost=18.11\n",
      "  40 -> 24, cost=8.60\n",
      "  41 -> 52, cost=11.18\n",
      "  42 -> 3, cost=12.21\n",
      "  43 -> 16, cost=9.22\n",
      "  44 -> 14, cost=23.09\n",
      "  45 -> 39, cost=10.82\n",
      "  46 -> 17, cost=18.44\n",
      "  47 -> 18, cost=18.25\n",
      "  48 -> 9, cost=13.15\n",
      "  49 -> 8, cost=7.28\n",
      "  50 -> 49, cost=17.46\n",
      "  51 -> 34, cost=7.81\n"
     ]
    }
   ],
   "source": [
    "mip_solver(all_nodes, customers, customer_demands, node_data, E_star, t0, d0, alpha, bar_alpha, R, Du, Tu, N_u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lp_relaxation_solver(all_nodes, customers, customer_demands, node_data, E_star, t0, d0, alpha, bar_alpha, R, Du, Tu, N_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
